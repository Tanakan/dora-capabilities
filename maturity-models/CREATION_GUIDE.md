# DORA Capabilities 成熟度モデル作成ガイド

このガイドは、test-automation.md (v22.0) と test-data-management.md (v1.0) の作成を通じて確立されたベストプラクティスをまとめたものです。

---

## 📋 基本原則

### 1. CLAUDE.mdガイドラインに準拠
- **成熟度レベル定義のみに絞る**
- 余計な説明、ベストプラクティス、移行ガイド、よくある課題は不要
- コード例は含めない

### 2. チェックリスト形式（AND条件）
- すべてのレベル到達条件は□チェックボックス形式
- 1つでも満たさない項目があれば未到達
- 定量的基準と定性的基準を混在させる

### 3. 開発者主導原則を明確にする
各レベルで開発者の関与度を明記:
- **レベル1**: 開発者が関与していない
- **レベル2**: 一部の開発者が関与し始める
- **レベル3**: 開発者主導が定着（DORA原則達成）
- **レベル4**: 開発者主導の文化が定着
- **レベル5**: 開発者主導の文化が組織全体に定着

---

## 🏗️ 構造テンプレート

### 標準構造（5軸評価フレームワーク）

```markdown
# [ケイパビリティ名] 成熟度モデル

## ケイパビリティ概要
[簡潔な説明 - 2-3文]

**カテゴリ**: [Climate for Learning / Fast Flow / Fast Feedback]
**DORA分類**: [コアケイパビリティ / その他]

---

## 評価軸の定義

### 1. [評価軸1名]

**何を測るか**: [1文で要約]

**なぜ重要か**:
- [理由1]
- [理由2]
- [理由3]

**評価方法**:
- [方法1]
- [方法2]

---

### 2. [評価軸2名]
[同様の構造]

---

[評価軸3, 4, 5も同様]

---

## テストタイプ別の成熟度評価
※ケイパビリティによってはこのセクションが不要な場合もある

### [分類1]（例: Unit Tests）

#### 評価軸1: [軸名]

**レベル1: 初期段階**
- □ [基準1]
- □ [基準2]

**レベル2: 管理段階**
- □ [基準1]
- □ [基準2]

**レベル3: 定義段階**
- □ [基準1]
- □ [基準2]

**レベル4: 定量管理段階**
- □ [基準1]
- □ [基準2]

**レベル5: 最適化段階**
- □ [基準1]
- □ [基準2]
- □ [基準3]

---

[評価軸2, 3, 4, 5も同様]

---

[分類2, 3, 4も同様]

---

## ヒートマップ評価方法

### 評価手順
1. **各分類の各評価軸を個別に評価**
2. **チェックリストですべて満たすレベルを特定**
3. **ヒートマップを作成**

### ヒートマップの色分け基準
- 🔴 **レベル1**: 初期段階（赤）
- 🟠 **レベル2**: 管理段階（オレンジ）
- 🟡 **レベル3**: 定義段階（黄色）- DORA推奨基準
- 🟢 **レベル4**: 定量管理段階（緑）
- 🔵 **レベル5**: 最適化段階（青）

---

**最終更新**: YYYY-MM-DD
**バージョン**: 1.0
```

---

## 🎯 ケイパビリティタイプ別の判断基準

### タイプA: 複数分類型（ヒートマップ化可能）

**該当例**: Test Automation, Test Data Management

**特徴**:
- 複数の分類軸（テストタイプ、環境タイプ等）が存在
- 各分類で成熟度が異なる可能性がある
- ヒートマップでマトリクス評価が可能

**構造**:
```
## テストタイプ別の成熟度評価
### Unit Tests
  #### 評価軸1-5
### Component/IT
  #### 評価軸1-5
### External Systems
  #### 評価軸1-5
### E2E
  #### 評価軸1-5
```

**ヒートマップ**: 4分類 × 5評価軸 = 20セル

---

### タイプB: 単一評価型（ヒートマップなし）

**該当例**: Continuous Integration, Deployment Automation

**特徴**:
- 分類軸が不要（組織全体で統一的に評価）
- 5つの評価軸のみで評価
- ヒートマップは不要（1次元評価）

**構造**:
```
## 成熟度評価

### 評価軸1: [軸名]
#### レベル1-5

### 評価軸2: [軸名]
#### レベル1-5

[評価軸3, 4, 5も同様]
```

**評価方法**: 5軸それぞれでレベル1-5を判定

---

## 📐 5つの評価軸の定義方法

### 1. 網羅性（Coverage）
**何を測るか**: 対象範囲の広さ、カバレッジ率

**典型的な基準**:
- レベル1: ほぼ存在しない（5%未満）
- レベル2: 一部カバー（20-30%）
- レベル3: 主要部分カバー（50-60%）
- レベル4: ほぼ全体カバー（75-80%）
- レベル5: 完全カバー（90-95%以上）

**例**:
- Test Automation: コードカバレッジ率、ユースケース自動化率
- Test Data: 全テストスイート実行に必要なデータの充足率

---

### 2. 質（Quality）
**何を測るか**: 実装の質、ベストプラクティス準拠度

**典型的な基準**:
- レベル1: 低品質、ベストプラクティス不在
- レベル2: 基本的な品質基準
- レベル3: ベストプラクティス準拠
- レベル4: 高度なパターン活用
- レベル5: 業界最高水準

**例**:
- Test Automation: テストパターン、振る舞い検証、独立性
- Test Data: データ多様性、本番データとの類似性、個人情報保護

---

### 3. 実行品質（Execution）
**何を測るか**: 実行速度、安定性、パフォーマンス

**典型的な基準**:
- レベル1: 測定なし
- レベル2: 測定開始、トレンド記録
- レベル3: 基準維持、改善タスク作成
- レベル4: トレンド分析、事前検知
- レベル5: 継続的最適化、ダッシュボード可視化

**例**:
- Test Automation: 実行時間、Flaky Test率
- Test Data: データ生成時間、データリセット時間

---

### 4. 開発者文化（Culture）
**何を測るか**: 開発者の主体的関与度

**典型的な基準**（DORA核心原則）:
- レベル1: 開発者が関与していない
- レベル2: 一部の開発者が関与し始める
- レベル3: 開発者主導が定着（DORA原則達成）
- レベル4: 開発者主導の文化が定着
- レベル5: 開発者主導の文化が組織全体に定着

**補足**:
- TDD/ATDD等の開発手法の実践度も文化の一部
- Unit Tests: TDD、E2E Tests: ATDD が典型例

---

### 5. 戦略（Strategy）
**何を測るか**: 計画性、文書化、継続的改善

**典型的な基準**:
- レベル1: 暗黙的（口頭、場当たり的）
- レベル2: 基本方針の文書化
- レベル3: 詳細定義、組織標準化
- レベル4: データドリブン、定期見直し
- レベル5: 継続的最適化、外部貢献

**例**:
- Test Automation: テスト戦略文書、定期見直し、優先度付け
- Test Data: データ管理戦略、パフォーマンス測定

---

## 🔢 数値基準の設定ガイドライン

### 基本原則
1. **段階的に厳しくする**: レベル1→5で連続的に改善
2. **業界標準を参照**: DORA、Google、Microsoft等のベンチマーク
3. **実現可能性を考慮**: レベル5は「理想」ではなく「達成可能な最高水準」

### Test Automation カバレッジ率の例（CLAUDE.md準拠）

| レベル | Unit Tests | Component/IT | External Systems | E2E |
|--------|------------|--------------|------------------|-----|
| 1 | 5%未満 | 0% | 0% | 0% |
| 2 | 30%以上 | 10%以上 | 10%以上 | 2-3ケース |
| 3 | 60%以上 | 50%以上 | 50%以上 | 30%以上 |
| 4 | 80%以上 | 75%以上 | 75%以上 | 50%以上 |
| 5 | 95%以上 | 90%以上 | 90%以上 | 70%以上 |

### 実行時間の例（DORA推奨）

| レベル | Unit Tests | Component/IT | External Systems | E2E |
|--------|------------|--------------|------------------|-----|
| 1 | 測定なし | 測定なし | 測定なし | 測定なし |
| 2 | 測定開始 | 測定開始 | 測定開始 | 測定開始 |
| 3 | 10分未満 | 15分未満 | 20分未満 | 30分未満 |
| 4 | 5分未満 | 10分未満 | 15分未満 | 20分未満 |
| 5 | 2分未満 | 5分未満 | 10分未満 | 15分未満 |

### Flaky Test率の例

| レベル | 基準 | 理由 |
|--------|------|------|
| 1-2 | 測定なし | 問題認識すらしていない |
| 3 | 2%未満 | 基本的な安定性（E2Eは5%） |
| 4 | 0.5%未満 | 高い安定性 |
| 5 | 0.1%未満 | ほぼゼロ |

**注**: E2E Testsはブラウザ・ネットワーク依存のため、基準を緩める

---

## ⚠️ よくある間違いと修正方法

### 1. 他のケイパビリティ項目の混入

**❌ 間違い**:
```markdown
## Test Automation
### 評価軸: CI/CD統合
- □ CIパイプラインで自動実行されている
- □ デプロイメントパイプラインに統合されている
```

**✅ 正しい**:
```markdown
## Test Automation
### 評価軸: 実行品質
- □ 実行時間が10分未満
- □ Flaky Test率が2%未満
```

**理由**: CI/CDは別ケイパビリティ。Test Automationは「テスト自体の成熟度」のみを評価。

---

### 2. 評価例・改善ガイドの記述

**❌ 間違い**:
```markdown
## 改善の優先順位付け
1. 赤いセル（レベル1）を最優先で改善
2. テストピラミッドの下層から改善
```

**✅ 正しい**:
```markdown
[このセクション自体を削除]
```

**理由**: CLAUDE.mdガイドライン「改善計画、移行ガイドは不要」

---

### 3. DoD（Definition of Done）の不適切な使用

**❌ 間違い**:
```markdown
### 評価軸: 質
**レベル1**:
- □ テストなしを完了の定義としている
```

**✅ 正しい**:
```markdown
### 評価軸: 開発者文化 または 戦略
**レベル1**:
- □ 開発者がテストを書いていない
```

**理由**: DoDは組織ポリシーであり、「質」の評価基準ではない。「文化」または「戦略」に属する。

---

### 4. 数値基準の矛盾

**❌ 間違い**:
```markdown
レベル4: 70%以上
レベル5: 75%以上
```

**✅ 正しい**:
```markdown
レベル4: 80%以上
レベル5: 95%以上
```

**理由**: CLAUDE.mdガイドラインに準拠。段階的に十分な差をつける。

---

### 5. 重複した記述

**❌ 間違い**:
```markdown
### 評価軸1: 網羅性
**レベル5**:
- □ Mutation Testingを導入

### 評価軸2: 質
**レベル5**:
- □ Mutation Testingを定期実行
```

**✅ 正しい**:
```markdown
### 評価軸2: 質（のみに記述）
**レベル5**:
- □ Mutation Testingを定期実行し、テストの有効性を検証
```

**理由**: Mutation Testingは「質」を評価する手法。「網羅性」ではない。

---

## 📝 作成手順（チェックリスト）

### ステップ1: DORA公式ドキュメントの確認
- [ ] DORA公式HTMLファイルを読む
- [ ] ケイパビリティのスコープを明確にする
- [ ] 他のケイパビリティとの境界を確認

### ステップ2: 構造決定
- [ ] タイプA（複数分類型）かタイプB（単一評価型）か判断
- [ ] タイプAの場合、分類軸を定義（テストタイプ、環境タイプ等）
- [ ] 5つの評価軸を定義

### ステップ3: 評価軸の定義作成
各評価軸で以下を記述:
- [ ] 何を測るか（1文）
- [ ] なぜ重要か（3-5項目）
- [ ] 評価方法（2-3項目）

### ステップ4: レベル定義作成
各分類・各評価軸で:
- [ ] レベル1-5のチェックリストを作成
- [ ] 定量的基準と定性的基準を混在
- [ ] 開発者主導原則を反映（評価軸4）
- [ ] 数値基準をCLAUDE.mdに準拠

### ステップ5: レビュー
- [ ] 他のケイパビリティ項目が混入していないか
- [ ] 評価例・改善ガイドが含まれていないか
- [ ] DoDの使い方が適切か
- [ ] 数値基準に矛盾がないか
- [ ] 重複した記述がないか

### ステップ6: ヒートマップ評価方法の追加
- [ ] 評価手順を記述
- [ ] 色分け基準を記述

### ステップ7: メタ情報の記載
- [ ] 最終更新日
- [ ] バージョン番号

---

## 📚 参考資料

### 既存の成熟度モデル
1. **test-automation.md (v22.0)**: タイプA、4テストタイプ × 5評価軸
2. **test-data-management.md (v1.0)**: タイプA、4テストタイプ × 5評価軸

### DORA公式リソース
- DORA公式サイト: https://dora.dev/
- DORA Capabilities: https://dora.dev/capabilities/
- State of DevOps Report

### 数値基準の参考
- CLAUDE.md: 103-126行（Unit Testカバレッジ率、自動化率、実行時間、Flaky Test率の目安）

---

## 🚀 次に作成すべきケイパビリティ

### 優先度1（コアケイパビリティ）
1. **Continuous Integration** - 既存ファイルあり、要更新
2. **Continuous Delivery**
3. **Deployment Automation**
4. **Version Control**

### 優先度2（Fast Feedback）
5. **Monitoring and Observability**
6. **Proactive Failure Notification**

### 優先度3（Climate for Learning）
7. **Learning Culture**
8. **Transformational Leadership**

---

**最終更新**: 2025-11-18
**バージョン**: 1.1 (具体例・評価例を削除: CLAUDE.mdガイドライン準拠)
**ベース**: test-automation.md v22.0, test-data-management.md v1.0
