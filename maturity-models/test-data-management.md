# テストデータ管理（Test Data Management）成熟度モデル

## ケイパビリティ概要

テストデータ管理は、自動テストスイート全体を実行するために必要なテストデータを、適切に利用可能にし、管理するプラクティスです。効果的なテストデータ管理により、テストの信頼性と効率性が向上し、開発速度が加速します。

**カテゴリ**: Fast Feedback（高速フィードバック）
**DORA分類**: その他のケイパビリティ

**DORA 3原則**:
1. **Adequate test data**: 十分なテストデータが利用可能
2. **On-demand acquisition**: 必要な時にデータを取得可能
3. **No constraints**: テストデータがテストを制約しない

---

## 評価軸の定義

### 1. データ可用性（Availability）

**何を測るか**: 自動テストスイート実行に必要な十分なテストデータが利用可能か

**なぜ重要か**:
- テストデータが不足すると、テストをスキップせざるを得なくなる
- 不十分なデータは、バグを見逃す原因となる
- 十分なデータがあることで、包括的なテストが可能になる

**評価方法**:
- テストデータの準備状況（手動 vs 自動）
- データ不足によるテストスキップの有無
- 全自動テストスイート実行に必要なデータの充足率

**具体例**:
- レベル1: 本番データコピー依存、データ不足でテストスキップ
- レベル3: 自動生成、全テストスイート実行可能
- レベル5: オンデマンド生成、データ不足ゼロ

---

### 2. オンデマンド性（On-demand）

**何を測るか**: 必要な時にテストデータを即座に取得・生成できるか

**なぜ重要か**:
- データ準備に時間がかかると、開発速度が低下する
- 手動データ準備は、テスト実行の障壁となる
- オンデマンド取得により、開発者が自律的にテストを実行できる

**評価方法**:
- データ取得にかかる時間（手動準備 vs 自動生成）
- データ取得方法（申請・承認 vs セルフサービス）
- 開発者ローカル環境でのデータ取得可否

**具体例**:
- レベル1: 申請・承認、数日待ち
- レベル3: API/ツールで即座に取得
- レベル5: テスト実行時に自動生成

---

### 3. データ品質（Quality）

**何を測るか**: テストデータの質、多様性、本番データとの類似性

**なぜ重要か**:
- 低品質なデータは、本番環境で発生するバグを見逃す
- 多様性のないデータは、エッジケースを検証できない
- 本番データに近いデータで、より信頼性の高いテストができる

**評価方法**:
- データの多様性（正常系のみ vs エッジケース・異常系）
- データの鮮度（静的 vs 定期更新）
- 個人情報保護対策（マスキング、匿名化）

**具体例**:
- レベル1: 手動作成、正常系のみ
- レベル3: 多様なパターン、エッジケース含む
- レベル5: 本番データ特性を反映、継続的更新

---

### 4. データ独立性（Isolation）

**何を測るか**: テスト間、環境間でデータが分離されているか

**なぜ重要か**:
- データ共有は、テストの不安定性（Flaky Test）の原因となる
- 並列実行時のデータ競合を防ぐ必要がある
- 環境ごとのデータ分離により、テストの再現性が向上する

**評価方法**:
- テスト間のデータ分離度（共有 vs 独立）
- 環境ごとのデータ分離（共有環境 vs 専用環境）
- データリセット機構の有無

**具体例**:
- レベル1: 共有環境、データ競合頻発
- レベル3: テストごとにデータリセット、独立実行
- レベル5: 完全分離、並列実行可能

---

### 5. 戦略（Strategy）

**何を測るか**: テストデータ管理戦略の文書化、定期的見直し

**なぜ重要か**:
- 戦略がないと、場当たり的なデータ管理になる
- 文書化により、チーム間で一貫性が保たれる
- 定期的見直しにより、継続的改善が可能になる

**評価方法**:
- データ管理戦略の文書化レベル（暗黙的 → 基本方針 → 詳細定義）
- 定期的な見直しの有無（四半期ごと等）
- データドリブンな優先度付け

**具体例**:
- レベル1: 暗黙的（口頭、場当たり的）
- レベル3: 詳細に定義（データ種類、生成方法、保持期間等）
- レベル5: 継続的最適化、データの価値を定量評価

---

## テストタイプ別の成熟度評価

### Unit Tests（単体テスト）

#### 評価軸1: データ可用性（Availability）

**レベル1: 初期段階**
- □ テストデータが手動で作成されている
- □ データ不足によりテストをスキップしている

**レベル2: 管理段階**
- □ Test Data Builder、Object Motherパターンを一部で使用している
- □ 主要な正常系データは準備されている

**レベル3: 定義段階**
- □ Test Data Builder、Factory、Object Motherが標準化されている
- □ すべてのテストケースに必要なデータが準備されている
- □ エッジケース・異常系データも含む

**レベル4: 定量管理段階**
- □ データ生成が完全に自動化されている
- □ データ不足によるテストスキップがゼロ

**レベル5: 最適化段階**
- □ テストごとに必要最小限のデータのみを生成している
- □ データ生成のパフォーマンスを継続的に最適化している

---

#### 評価軸2: オンデマンド性（On-demand）

**レベル1: 初期段階**
- □ テストデータを手動で準備している
- □ データ準備に時間がかかる（数時間〜数日）

**レベル2: 管理段階**
- □ 一部のデータはコード内で生成している
- □ 頻繁に使うデータはテンプレート化されている

**レベル3: 定義段階**
- □ すべてのテストデータがコード内で生成される
- □ 開発者が自律的にデータを作成できる

**レベル4: 定量管理段階**
- □ テスト実行時に自動生成される（事前準備不要）
- □ データ生成時間が1秒未満

**レベル5: 最適化段階**
- □ ランダムデータ生成、Property-based Testingを活用している
- □ データ生成ライブラリが組織標準として整備されている

---

#### 評価軸3: データ品質（Quality）

**レベル1: 初期段階**
- □ 正常系の単純なデータのみ
- □ エッジケース・異常系データがない
- □ データのバリエーションが少ない

**レベル2: 管理段階**
- □ 主要なエッジケースデータが含まれている
- □ 異常系データを一部含む

**レベル3: 定義段階**
- □ 包括的なエッジケース・異常系データを含む
- □ 境界値テストデータが体系的に整備されている
- □ データのバリエーションが豊富（正常系、異常系、エッジケース）

**レベル4: 定量管理段階**
- □ パラメータ化テストで多様なデータパターンを検証している
- □ 本番で発生したバグのデータパターンをテストデータに反映している

**レベル5: 最適化段階**
- □ Property-based Testingでデータパターンを網羅的に検証している
- □ テストデータの品質メトリクスを測定し、継続的に改善している

---

#### 評価軸4: データ独立性（Isolation）

**レベル1: 初期段階**
- □ テスト間でデータを共有している
- □ テスト実行順序に依存している

**レベル2: 管理段階**
- □ 一部のテストはデータを独立して生成している
- □ 共有データによる競合を認識しているが、対処していない

**レベル3: 定義段階**
- □ 各テストが独立したデータを使用している
- □ テストは任意の順序で実行可能
- □ 並列実行時にデータ競合が発生しない

**レベル4: 定量管理段階**
- □ テストごとにデータをセットアップ・クリーンアップしている
- □ テストの独立性が自動検証されている

**レベル5: 最適化段階**
- □ 完全に独立したテスト（並列実行、ランダム順序実行が標準）
- □ データ依存によるFlaky Testがゼロ

---

#### 評価軸5: 戦略（Strategy）

**レベル1: 初期段階**
- □ テストデータ戦略が暗黙的（口頭、場当たり的）

**レベル2: 管理段階**
- □ テストデータ戦略が文書化されている（基本方針レベル）
- □ Test Data Builderの使用を推奨している

**レベル3: 定義段階**
- □ テストデータ戦略が詳細に定義されている（パターン、ベストプラクティス、生成方法等）
- □ Test Data Builder、Factoryパターンが組織標準として整備されている

**レベル4: 定量管理段階**
- □ データ生成パフォーマンスを測定している
- □ テストデータ戦略を定期的に見直している（四半期ごと等）

**レベル5: 最適化段階**
- □ テストデータの価値を定量評価し、継続的に最適化している
- □ データ生成ライブラリをOSS化し、組織外にも貢献している

---

### Component/Integration Tests（コンポーネント/統合テスト）

#### 評価軸1: データ可用性（Availability）

**レベル1: 初期段階**
- □ テストデータが存在しない、または手動で準備している
- □ データ不足によりテストをスキップしている

**レベル2: 管理段階**
- □ 主要なユースケースのデータは準備されている
- □ Test Fixtureを一部で使用している

**レベル3: 定義段階**
- □ すべてのユースケースに必要なデータが準備されている
- □ Test Fixture、Database Seedingが標準化されている
- □ 正常系・異常系データが含まれている

**レベル4: 定量管理段階**
- □ データ生成が完全に自動化されている
- □ データ不足によるテストスキップがゼロ

**レベル5: 最適化段階**
- □ テストごとに必要最小限のデータセットのみを準備している
- □ データ準備のパフォーマンスを継続的に最適化している

---

#### 評価軸2: オンデマンド性（On-demand）

**レベル1: 初期段階**
- □ テストデータを手動で準備している
- □ データベースへの手動データ投入が必要

**レベル2: 管理段階**
- □ SQLスクリプトでデータを準備している
- □ 一部のデータはAPIで生成している

**レベル3: 定義段階**
- □ テスト実行前に自動でデータをセットアップしている
- □ アプリケーションのAPIを使ってデータを生成している
- □ 開発者ローカル環境でもデータ生成可能

**レベル4: 定量管理段階**
- □ テスト実行時に自動生成される（事前準備不要）
- □ データ生成時間が10秒未満

**レベル5: 最適化段階**
- □ インメモリDB（H2、SQLite等）で高速にデータを準備している
- □ データ生成フレームワークが組織標準として整備されている

---

#### 評価軸3: データ品質（Quality）

**レベル1: 初期段階**
- □ 正常系の単純なデータのみ
- □ データの関連性が不整合（外部キー違反等）

**レベル2: 管理段階**
- □ データの関連性が整合している
- □ 主要な異常系データを含む

**レベル3: 定義段階**
- □ 包括的な異常系・エッジケースデータを含む
- □ 複数コンポーネント間の連携パターンを網羅している
- □ データの整合性が保証されている

**レベル4: 定量管理段階**
- □ 本番で発生したバグのデータパターンをテストデータに反映している
- □ データのバリエーションを定量的に管理している

**レベル5: 最適化段階**
- □ 本番データの特性（分布、サイズ等）を反映したデータを生成している
- □ テストデータの品質メトリクスを測定し、継続的に改善している

---

#### 評価軸4: データ独立性（Isolation）

**レベル1: 初期段階**
- □ 共有データベースを使用している
- □ テスト間でデータが競合している

**レベル2: 管理段階**
- □ テストごとにトランザクションロールバックしている
- □ 一部のテストは独立したデータを使用している

**レベル3: 定義段階**
- □ 各テストが独立したデータセットを使用している
- □ テスト後にデータをクリーンアップしている
- □ 並列実行時にデータ競合が発生しない

**レベル4: 定量管理段階**
- □ テストごとに専用のスキーマ・テーブルを使用している
- □ インメモリDBまたはTest Containersで完全分離されている

**レベル5: 最適化段階**
- □ 完全に独立したテスト（並列実行、ランダム順序実行が標準）
- □ データ依存によるFlaky Testがゼロ

---

#### 評価軸5: 戦略（Strategy）

**レベル1: 初期段階**
- □ テストデータ戦略が暗黙的（口頭、場当たり的）

**レベル2: 管理段階**
- □ テストデータ戦略が文書化されている（基本方針レベル）
- □ Test Fixture、Database Seedingの使用を推奨している

**レベル3: 定義段階**
- □ テストデータ戦略が詳細に定義されている（データ準備方法、クリーンアップ方法、パターン等）
- □ データ準備フレームワークが組織標準として整備されている

**レベル4: 定量管理段階**
- □ データ準備パフォーマンスを測定している
- □ テストデータ戦略を定期的に見直している（四半期ごと等）

**レベル5: 最適化段階**
- □ テストデータの価値を定量評価し、継続的に最適化している
- □ データ準備のベストプラクティスを外部発信している（カンファレンス、ブログ等）

---

### External Systems Tests（外部システム統合テスト）

#### 評価軸1: データ可用性（Availability）

**レベル1: 初期段階**
- □ テストデータが存在しない、または手動で準備している
- □ 本番環境のデータに依存している

**レベル2: 管理段階**
- □ 主要な外部連携のデータは準備されている
- □ 外部システムのモック/スタブデータを一部で使用している

**レベル3: 定義段階**
- □ すべての外部連携に必要なデータが準備されている
- □ Test Containers、WireMock等でデータを管理している
- □ 正常系・異常系（タイムアウト、エラーレスポンス等）データが含まれている

**レベル4: 定量管理段階**
- □ データ生成が完全に自動化されている
- □ データ不足によるテストスキップがゼロ

**レベル5: 最適化段階**
- □ 本番環境の外部システム挙動を反映したデータを生成している
- □ データ準備のパフォーマンスを継続的に最適化している

---

#### 評価軸2: オンデマンド性（On-demand）

**レベル1: 初期段階**
- □ 外部システムのテストデータを手動で準備している
- □ データベースへの手動データ投入が必要

**レベル2: 管理段階**
- □ SQLスクリプト、モックサーバー設定で一部準備している
- □ データ準備に時間がかかる（数分〜数時間）

**レベル3: 定義段階**
- □ テスト実行前に自動でデータをセットアップしている
- □ Test Containers、WireMockが自動起動される
- □ 開発者ローカル環境でもデータ生成可能

**レベル4: 定量管理段階**
- □ テスト実行時に自動生成される（事前準備不要）
- □ データ生成時間が30秒未満

**レベル5: 最適化段階**
- □ 外部システムのモック/スタブが高速に起動する
- □ データ生成フレームワークが組織標準として整備されている

---

#### 評価軸3: データ品質（Quality）

**レベル1: 初期段階**
- □ 正常系の単純なレスポンスデータのみ
- □ 異常系（タイムアウト、エラー等）データがない

**レベル2: 管理段階**
- □ 主要な異常系レスポンスを含む
- □ 外部システムのレスポンス形式に準拠している

**レベル3: 定義段階**
- □ 包括的な異常系・エッジケースレスポンスを含む
- □ タイムアウト、リトライ、エラーハンドリングのテストデータが整備されている
- □ 本番環境の外部システム仕様に準拠している

**レベル4: 定量管理段階**
- □ 本番で発生した外部システムエラーパターンをテストデータに反映している
- □ 外部システムの仕様変更を定期的にキャッチアップしている

**レベル5: 最適化段階**
- □ 本番環境の外部システム挙動（レスポンス時間、エラー率等）を反映している
- □ カオスエンジニアリングで障害シナリオを継続的にテストしている

---

#### 評価軸4: データ独立性（Isolation）

**レベル1: 初期段階**
- □ 共有テスト環境の外部システムを使用している
- □ テスト間でデータが競合している

**レベル2: 管理段階**
- □ 外部システムのモック/スタブを一部使用している
- □ データ競合を認識しているが、対処していない

**レベル3: 定義段階**
- □ 各テストが独立した外部システムモック/スタブを使用している
- □ Test Containers、WireMockで環境分離されている
- □ 並列実行時にデータ競合が発生しない

**レベル4: 定量管理段階**
- □ テストごとに専用の外部システムインスタンスが起動する
- □ テスト後に自動でクリーンアップされる

**レベル5: 最適化段階**
- □ 完全に独立したテスト（並列実行、ランダム順序実行が標準）
- □ データ依存によるFlaky Testがゼロ

---

#### 評価軸5: 戦略（Strategy）

**レベル1: 初期段階**
- □ 外部システムテストデータ戦略が暗黙的（口頭、場当たり的）

**レベル2: 管理段階**
- □ 外部システムテストデータ戦略が文書化されている（基本方針レベル）
- □ Test Containers、WireMockの使用を推奨している

**レベル3: 定義段階**
- □ 外部システムテストデータ戦略が詳細に定義されている（モック方法、障害シナリオ、データ準備方法等）
- □ 外部システムモックフレームワークが組織標準として整備されている

**レベル4: 定量管理段階**
- □ データ準備パフォーマンスを測定している
- □ 外部システムテストデータ戦略を定期的に見直している（四半期ごと等）

**レベル5: 最適化段階**
- □ 外部システムテストデータの価値を定量評価し、継続的に最適化している
- □ 外部システムモックのベストプラクティスを外部発信している

---

### E2E Tests（E2Eテスト）

#### 評価軸1: データ可用性（Availability）

**レベル1: 初期段階**
- □ テストデータが存在しない、または手動で準備している
- □ 本番環境のデータに依存している

**レベル2: 管理段階**
- □ 最頻度のユースケースのデータは準備されている
- □ 本番データのコピーを使用している

**レベル3: 定義段階**
- □ すべてのユースケースに必要なデータが準備されている
- □ データリセット機構が整備されている
- □ 正常系・異常系データが含まれている

**レベル4: 定量管理段階**
- □ データ生成が完全に自動化されている
- □ データ不足によるテストスキップがゼロ

**レベル5: 最適化段階**
- □ 本番データの特性（データ量、分布等）を反映したデータを生成している
- □ データ準備のパフォーマンスを継続的に最適化している

---

#### 評価軸2: オンデマンド性（On-demand）

**レベル1: 初期段階**
- □ テストデータを手動で準備している
- □ データ準備に時間がかかる（数時間〜数日）

**レベル2: 管理段階**
- □ SQLスクリプト、管理画面で一部準備している
- □ データ準備が自動化されているが、時間がかかる（数十分）

**レベル3: 定義段階**
- □ テスト実行前に自動でデータをセットアップしている
- □ アプリケーションのAPIを使ってデータを生成している
- □ データ生成時間が5分未満

**レベル4: 定量管理段階**
- □ テスト実行時に自動生成される（事前準備不要）
- □ データ生成時間が2分未満

**レベル5: 最適化段階**
- □ データ生成を並列化し、高速化している
- □ データ生成フレームワークが組織標準として整備されている

---

#### 評価軸3: データ品質（Quality）

**レベル1: 初期段階**
- □ 正常系の単純なデータのみ
- □ 個人情報保護対策がされていない本番データを使用している

**レベル2: 管理段階**
- □ 主要なユーザージャーニーのデータを含む
- □ 個人情報をマスキングした本番データコピーを使用している

**レベル3: 定義段階**
- □ 包括的なユーザージャーニーデータを含む
- □ エッジケース・異常系データが整備されている
- □ 個人情報が完全に匿名化されている

**レベル4: 定量管理段階**
- □ 本番で発生したバグのユーザージャーニーをテストデータに反映している
- □ 本番データの特性（データ量、分布等）を定期的に分析し、反映している

**レベル5: 最適化段階**
- □ 本番環境と同等のデータ量・分布でテストしている
- □ テストデータの品質メトリクスを測定し、継続的に改善している

---

#### 評価軸4: データ独立性（Isolation）

**レベル1: 初期段階**
- □ 共有テスト環境を使用している
- □ テスト間でデータが競合している

**レベル2: 管理段階**
- □ テスト後に手動でデータをクリーンアップしている
- □ データ競合を認識しているが、自動対処はしていない

**レベル3: 定義段階**
- □ 各テストが独立したデータセットを使用している
- □ テスト後に自動でデータをリセットしている
- □ 並列実行時にデータ競合が発生しない

**レベル4: 定量管理段階**
- □ テストごとに専用の環境・データベースを使用している
- □ テスト前後のデータリセットが1分未満で完了する

**レベル5: 最適化段階**
- □ 完全に独立したテスト（並列実行、ランダム順序実行が標準）
- □ データ依存によるFlaky Testがゼロ

---

#### 評価軸5: 戦略（Strategy）

**レベル1: 初期段階**
- □ E2Eテストデータ戦略が暗黙的（口頭、場当たり的）

**レベル2: 管理段階**
- □ E2Eテストデータ戦略が文書化されている（基本方針レベル）
- □ 本番データコピー、マスキングの使用を推奨している

**レベル3: 定義段階**
- □ E2Eテストデータ戦略が詳細に定義されている（データ準備方法、リセット方法、個人情報保護方針等）
- □ データ準備・リセットフレームワークが組織標準として整備されている

**レベル4: 定量管理段階**
- □ データ準備パフォーマンスを測定している
- □ E2Eテストデータ戦略を定期的に見直している（四半期ごと等）

**レベル5: 最適化段階**
- □ E2Eテストデータの価値を定量評価し、継続的に最適化している
- □ データ準備のベストプラクティスを外部発信している（カンファレンス、ブログ等）

---

## ヒートマップ評価方法

### 評価手順

1. **各テストタイプの各評価軸を個別に評価**
   - 4テストタイプ × 5評価軸 = 20セルを評価
   - 各セルでレベル1〜5を判定

2. **チェックリストですべて満たすレベルを特定**
   - 該当レベルのすべての□にチェックが入る場合のみ、そのレベルに到達
   - 1つでも満たさない項目があれば、そのレベルには未到達

3. **ヒートマップを作成**
   - 各セルをレベルに応じて色分け

### ヒートマップの色分け基準

- 🔴 **レベル1**: 初期段階（赤）
- 🟠 **レベル2**: 管理段階（オレンジ）
- 🟡 **レベル3**: 定義段階（黄色）- DORA推奨基準
- 🟢 **レベル4**: 定量管理段階（緑）
- 🔵 **レベル5**: 最適化段階（青）

### ヒートマップ評価例

```
テストタイプ           可用性  On-demand  品質  独立性  戦略
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
Unit Tests            🟢   🔵   🟡   🟢   🟡
Component/IT          🟡   🟡   🟠   🟡   🟠
External Systems      🟠   🟠   🟠   🟡   🟠
E2E Tests             🟡   🟠   🟠   🟠   🟡
```

---

**最終更新**: 2025-11-18
**バージョン**: 1.0
