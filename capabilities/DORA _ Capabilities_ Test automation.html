<!doctype html>
<meta charset="utf-8">
<html lang="en">
    <head>

<script async src="https://www.googletagmanager.com/gtag/js?id=G-HWLXSJLRVQ"></script>
<script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());

    gtag('config', 'G-HWLXSJLRVQ');
</script>



<title>DORA | Capabilities: Test automation</title>



<link rel="stylesheet" href="/scss/main.b00d7e76e1b3edfc695882ae0c694e4834222cea0e416a1a9d9e2caf73f522d4.css" integrity="sha256-sA1&#43;duGz7fxpWIKuDGlOSDQiLOoOQWoanZ4sr3P1ItQ=">
<link rel="stylesheet" href="/css/quickcheck-variables.893d3e3acc263f6c37987aaa860c6ed32a88b3a286d6409d4fd06f0c1859cb82.css" integrity="sha256-iT0&#43;OswmP2w3mHqqhgxu0yqIs6KG1kCdT9BvDBhZy4I=">


<meta name="description" content="DORA is a long running research program that seeks to understand the capabilities that drive software delivery and operations performance. DORA helps teams apply those capabilities, leading to better organizational performance.">
<meta name="keywords" content="DevOps, Lead time, Deploy frequency, Change fail rate, MTTR, Time to restore, metrics, DORA">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css?family=Google+Material+Icons&amp;lang=en" rel="stylesheet">


<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/site.webmanifest">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">
<meta name="msapplication-TileColor" content="#2d89ef">
<meta name="theme-color" content="#ffffff">


<meta property="og:url" content="https://dora.dev">
<meta property="og:type" content="website">
<meta property="og:title" content="DORA | Capabilities: Test automation">
<meta property="og:description" content="DORA is a long running research program that seeks to understand the capabilities that drive software delivery and operations performance. DORA helps teams apply those capabilities, leading to better organizational performance.">
<meta property="og:image" content="/img/misc/dora_social_image.png">


<meta name="twitter:card" content="summary_large_image">
<meta property="twitter:domain" content="dora.dev">
<meta property="twitter:url" content="https://dora.dev">
<meta name="twitter:title" content="DORA | Capabilities: Test automation">
<meta name="twitter:description" content="DORA is a long running research program that seeks to understand the capabilities that drive software delivery and operations performance. DORA helps teams apply those capabilities, leading to better organizational performance.">
<meta name="twitter:image" content="/img/misc/dora_social_image.png">



<script>
    document.addEventListener("DOMContentLoaded", function () {
        let headings = document.querySelectorAll("h1[id], h2[id], h3[id], h4[id], h5[id], h6[id]");
        headings.forEach((heading) => {
            addAnchorLink(heading);
        })

        highlightSelectedHeading();
    });

    function addAnchorLink(heading) {
        
        let anchorText = heading.getAttribute('id');

        let anchorLink = Object.assign(document.createElement('a'),{
            href: '#' + anchorText,
            className: 'heading-link',
            innerHTML: '<span class="google-material-icons">link</span> <span class="click-to-copy">click to copy link</span>',
        });
        heading.append(anchorLink);
        
        heading.addEventListener("mouseover",
            (event) => { anchorLink.style.visibility='visible' }
        );
        heading.addEventListener("mouseout",
            (event) => { 
                anchorLink.style.visibility='hidden';
                anchorLink.lastChild.innerHTML='click to copy link';
            }
        );
        
        anchorLink.addEventListener("mouseover",
            (event) => {
                anchorLink.lastChild.style.visibility='visible';
            }
        );
        anchorLink.addEventListener("mouseout",
            (event) => {
                anchorLink.lastChild.style.visibility='hidden';
            }
        );
        anchorLink.addEventListener("click",
            (event) => {
                event.preventDefault();
                let currentBaseUrl = location.href.split('#')[0];
                let targetURL = `${currentBaseUrl}#${anchorText}`;
                navigator.clipboard.writeText(targetURL);
                console.debug(`copied to clipboard: ${targetURL}`);
                anchorLink.lastChild.innerHTML='<em>copied!</em>';
            }
        );
    };

    function highlightSelectedHeading() {
        
        let selectedAnchor = location.href.split('#')[1];
            if (selectedAnchor) {
                document.querySelector(`#${selectedAnchor}`).classList.add('heading-highlight');
            }
    }
</script>

<style>

    .heading-link {
        visibility: hidden;
        text-decoration: none;
        padding-left:1rem;
    }

    .heading-link .google-material-icons {
        color:#666;
    }

    .heading-link .google-material-icons:hover {
        color:#1a73e8;
    }

    .click-to-copy {
        font-size:.75rem;
        color:#666;
        text-decoration: none;
        visibility: hidden;
        vertical-align: middle;
    }

     
     
</style></head>
    <body><header>
  <div class="navContainer">
    <div class="dora-logo-link">
      <a href="/"><img src="/img/dora-logo.svg" height="48px" class="dora-logo" alt="DORA"></a>
    </div>
    <nav>
      <ul class="menuLinksDesktop">
        <li><a href="/publications/" >Publications</a>
        </li>
        <li><a href="/research/" >Research</a></li>
        <li><a href="/capabilities/" class="active" >Capabilities</a>
        </li>
        <li><a href="/guides/" >Guides</a></li>
        <li><a href="/quickcheck/" >Quick Check</a>
        </li>
        <li id="searchLinkDesktop"><a class="google-material-icons" id="searchIcon"
            aria-label="Search dora.dev">search</a></li>
        </li>
        <li><a href="https://dora.community/" target="_blank">Community&nbsp;&nbsp;<span
              class="google-material-icons open_in_new">open_in_new</span></a></li>
      </ul>
      <div id="searchInputPopover" popover>
        <div id="searchInputPopoverFields"><form action="/search/" method="get" id="searchForm">
    <div class="searchInputContainer"><input type="search" name="q" class="searchQuery"
            placeholder="Search dora.dev for..." required><input type="submit" value="search" id="searchButton"
            class="searchButton" /></div>
</form></div>
      </div>
      <div class="page-overlay"></div>
      <label id="hamburgerContainer">
        <input type="checkbox" id="mobileMenuController" onchange="console.log(this.checked)" />
        <span class="google-material-icons" aria-label="menu" id="hamburgerIcon">
          <span class="menu">menu</span>
          <span class="close">close</span>
        </span>
      </label>
    </nav>
  </div>
</header>
<div class="menuLinksMobile">
  <ul>
    <li><a href="/publications/" >Publications</a>
    </li>
    <li><a href="/research/" >Research</a></li>
    <li><a href="/capabilities/" class="active" >Capabilities</a>
    </li>
    <li><a href="/guides/" >Guides</a></li>
    <li><a href="/quickcheck/" >Quick Check</a>
    </li>
    <li id="searchLinkMobile"><a href="/search/" >Search</a>
    </li>
    <li><a href="https://dora.community/" target="_blank">Community&nbsp;&nbsp;<span
          class="google-material-icons open_in_new">open_in_new</span></a></li>
  </ul>
</div>

<script>
  document.querySelector('#searchIcon').addEventListener('click', (e) => {
    e.preventDefault();
    document.querySelector('#searchInputPopover').showPopover();
    document.querySelector('#searchInputPopover .searchQuery').focus();
  })
</script>



<main>



<link rel="stylesheet" href="/scss/capabilities.47c8706bd7e90133e0a9341ee137c36b14843f0a2fdaf7a24da49e16caeb479c.css" integrity="sha256-R8hwa9fpATPgqTQe4TfDaxSEPwov2veiTaSeFsrrR5w=">
<h4><a href="/capabilities">Capabilities</a>: fast feedback</h4>
<h1>
    Test automation
    <a class="core" href='/research/'>core</a>
</h1>

<section class="hasSidebar">
    <article>
        <p>The key to building quality into software is getting fast feedback on the impact
of changes throughout the software delivery lifecycle. Traditionally, teams
relied on manual testing and code inspection to verify systems&rsquo; correctness.
These inspections and tests typically occurred in a separate phase after &ldquo;dev
complete.&rdquo; This approach has the following drawbacks:</p>
<ul>
<li>Manual regression testing is time-consuming to execute and expensive to
perform, which makes it a bottleneck in the process. Software can&rsquo;t be
released frequently and developers can&rsquo;t get quick feedback.</li>
<li>Manual tests and inspections are not reliable, because people are poor at
repetitive tasks like manual regression tests, and it is hard to predict the
impact of changes on a complex software system through inspection.</li>
<li>Once software is &ldquo;dev complete&rdquo;, developers have to wait a long time to get
feedback on their changes. This usually results in substantial work to
triage defects and fix them. Performance, security, and reliability problems
often require design changes that are even more expensive to address when
discovered at this stage.</li>
<li>Long feedback cycles also make it harder for developers to learn how to
build quality code, and under schedule pressure development teams can
sometimes treat quality as &ldquo;somebody else&rsquo;s problem&rdquo;.</li>
<li>When developers aren&rsquo;t responsible for testing their own code it&rsquo;s hard for
them to learn how to write testable code.</li>
<li>For systems that evolve over time, keeping test documentation up to date
requires considerable effort.</li>
</ul>
<p>Instead, teams should:</p>
<ul>
<li>Perform all types of testing continuously throughout the software delivery
lifecycle.</li>
<li>Create and curate fast, reliable suites of automated tests which are run as
part of your
<a href="https://continuousdelivery.com/implementing/patterns/#the-deployment-pipeline" target="_blank" >continuous delivery pipelines</a>.</li>
</ul>
<p>Not only does this help teams build (and learn how to build) high quality
software faster, DORA&rsquo;s research shows that it also drives improved software
stability, reduced team burnout, and lower deployment pain.</p>
<h2 id="how-to-implement-automated-testing">How to implement automated testing</h2>
<p>To build quality into the software, you must continually run both automated and
manual tests throughout the delivery process to validate the functionality and
architecture of the system under development. This discipline has both an
organizational and a technical component. Organizationally, DORA&rsquo;s research
finds that teams do better when they:</p>
<ul>
<li>Allow testers to work alongside developers throughout the software
development and delivery process. (Note that &ldquo;tester&rdquo; is a role, not
necessarily a full-time job, although this is a common pattern discussed
below.)</li>
<li>Perform manual test activities such as exploratory testing, usability
testing, and acceptance testing throughout the delivery process.</li>
<li>Continuously review and improve test suites to better find defects and keep
complexity and cost under control.</li>
<li>Have developers practice test-driven development by writing unit tests before
writing production code for all changes to the codebase</li>
<li>Keep the test suite fast. Developers should be able to get feedback from
automated tests in less than ten minutes both on local workstations and
from the continuous integration system.</li>
</ul>
<p>A key technical activity is building and maintaining a set of automated test
suites, including:</p>
<ul>
<li><strong>Unit tests</strong>. These typically test a single method, class, or function in
isolation, providing assurance to developers that their code operates as
designed. To ensure that the code is testable and tests are maintainable,
write your unit tests before writing code, a technique known as
<a href="http://www.jamesshore.com/v2/books/aoad2" target="_blank" >test-driven development</a>
(TDD).</li>
<li><strong>Acceptance tests</strong>: These typically test a running app or service (usually
with dependencies replaced by
<a href="https://testing.googleblog.com/2013/07/testing-on-toilet-know-your-test-doubles.html" target="_blank" >test doubles</a>)
to provide assurance that a higher level of functionality operates as
designed and that regression errors have not been introduced. Example
acceptance tests might check for the business acceptance criteria for a user
story or the correctness of an API. Write these tests as part of the
development process. No one should be able to declare their work &ldquo;dev
complete&rdquo; unless automated acceptance tests are passing.</li>
</ul>
<p>The following diagram,
<a href="http://www.exampler.com/old-blog/2003/08/22/#agile-testing-project-2" target="_blank" >initially created by Brian Marick</a>
and later referenced in the book
<a href="https://books.google.com/books/about/Agile_Testing.html?id=68_lhPvoKS8C" target="_blank" ><em>Agile Testing: A Practical Guide for Testers and Agile Teams</em></a>,
shows the types of automated and manual tests to run.</p>
<p><img src="ta-image1.png" alt="image"style="max-width:100%"
  ></p>
<p>The automated tests highlighted in the preceding diagram fit in a
<a href="/capabilities/continuous-delivery" >continuous delivery</a>
<a href="https://continuousdelivery.com/implementing/patterns/#the-deployment-pipeline" target="_blank" >deployment pipeline</a>.
In such pipelines, every change runs a build that creates software packages,
executes unit tests, and possibly performs other checks, such as static
analysis. After these packages pass the first stage, more comprehensive
automated acceptance tests, and likely some nonfunctional tests such as
performance tests and vulnerability scans, run against automatically deployed
running software. Any build that passes the acceptance stage is then typically
made available for manual exploration and usability testing. Finally, if no
errors are found in these manual steps, the app is considered releasable.</p>
<p>Running tests continuously as part of a pipeline contributes to quick feedback
for developers, a short lead time from check-in to release, and a low error rate
in production environments. Developers have most of their work validated in a
matter of minutes, instead of days or weeks, so they can fix bugs as soon as
possible.</p>
<p>The following diagram shows an example of a simple linear deployment pipeline.
In this example, green means no problems were found, and red means that one or
more problems were discovered.</p>
<p><img src="ta-image3.png" alt="image"style="max-width:100%"
  ></p>
<p>In the deployment pipeline pattern, every change creates a release candidate and
the quick feedback loop helps to catch problems as early in the process as
possible. When a package reaches the end of the pipeline and the team still
doesn&rsquo;t feel comfortable with releasing it, or if they discover defects in
production, the pipeline must be improved, perhaps by adding or updating tests.</p>
<h2 id="common-pitfalls">Common pitfalls</h2>
<ul>
<li>
<p><strong>Not having developers involved in testing.</strong> DORA&rsquo;s research shows that
when developers are primarily responsible for creating and maintaining
suites of automated tests, and when it is easy for developers to fix
acceptance test failures, this drives improved performance. When other
groups own the test automation, two problems often arise:</p>
<ul>
<li><strong>Test suites are frequently in a broken state</strong>. Code changes might
require tests to be updated. If developers are not responsible for test
automation, the build pipeline stays broken until the responsible team
fixes the tests.</li>
<li><strong>Developers write code that is hard to test.</strong> Developers tend to solve
the problem they are given without thinking about how it will be tested.
This can lead to poorly designed code and expensive, hard-to-maintain
test suites.</li>
</ul>
<p>Testers and QA teams continue to have an important role in this way of
working. Testers have a unique perspective on the system because they
understand how users interact with it. It&rsquo;s a good practice to pair testers
with developers to create and evolve the suites of automated tests, using
screen sharing tools if teams are not physically colocated. This way, they
can learn from each other and solve problems in real time. Testers also play
an essential role performing exploratory testing and usability testing, as
well as helping to curate test suites.</p>
</li>
<li>
<p><strong>Failing to curate your test suites.</strong> Make sure you continuously review
and improve your test suites to better find defects and keep complexity and
cost under control. For example:</p>
<ul>
<li>Acceptance test suites should typically represent real
<a href="https://testing.googleblog.com/2016/09/testing-on-toilet-what-makes-good-end.html" target="_blank" >end-to-end</a>
user journeys through the system, rather than just collections of
automated acceptance criteria. As your product evolves, so will these
scenarios, and the test suites validating them. For more information on
this process, see the video
<a href="https://www.youtube.com/watch?v=qYfI2-bC6LA" target="_blank" >Setting a Foundation For Successful Test Automation</a>
by Angie Jones.</li>
<li>If every time you change your code you must also change multiple unit
tests, you&rsquo;re probably
<a href="https://martinfowler.com/articles/mocksArentStubs.html" target="_blank" >over-relying on mocking</a>,
or failing to prune your unit test suite.</li>
<li>Keep your test suites well-factored. If every change to your UI causes
multiple acceptance tests to fail, use the
<a href="https://martinfowler.com/bliki/PageObject.html" target="_blank" >page object pattern</a>
to decouple your tests from the system under test.</li>
<li>If your tests are expensive to maintain, this could point to problems
with your software&rsquo;s
<a href="/capabilities/loosely-coupled-teams" >architecture</a>. Make sure
you continue to invest in making your software easy to test, including
incorporating
<a href="https://refactoring.com/" target="_blank" >refactoring</a>
into your team&rsquo;s daily work.</li>
</ul>
</li>
<li>
<p><strong>Having the wrong proportion of unit and acceptance tests.</strong> A specific
design goal of an automated test suite is to find errors as early as
possible. This is why faster-running unit tests run before slower-running
acceptance tests, and both are run before any manual testing.</p>
<p>You should find errors with the fastest category of test. When you find an
error in an acceptance test or during exploratory testing, add a unit test
to make sure this error is caught faster, earlier, and cheaper next time.
Mike Cohn described the ideal
<a href="https://www.google.com/books/edition/Succeeding_with_Agile/IdT6AgAAQBAJ" target="_blank" >test automation pyramid</a>,
shown in the following diagram, where most of the errors are caught using
unit testing.</p>
<p><img src="ta-image2.png" alt="image"style="max-width:100%"
  ></p>
</li>
<li>
<p><strong>Tolerating unreliable tests.</strong> Tests should be reliable: that is, when the
tests pass we should be confident the software is releasable, and test
failures should indicate a real defect. In particular, don&rsquo;t tolerate flaky
tests.
<a href="https://testing.googleblog.com/2016/05/flaky-tests-at-google-and-how-we.html" target="_blank" >Read about Google&rsquo;s mitigation strategy for flaky tests</a>.</p>
</li>
</ul>
<h2 id="ways-to-improve-test-automation">Ways to improve test automation</h2>
<p>If your organization doesn&rsquo;t yet have a culture of unit testing by developers,
don&rsquo;t worry. Unit testing wasn&rsquo;t a widespread practice at Google in its early
years. The current culture of comprehensive unit testing was driven by a group
of volunteers at Google called the Testing Grouplet.
<a href="https://martinfowler.com/articles/testing-culture.html#google" target="_blank" >Read how they helped drive the adoption of unit testing</a>
by building a community of practice focused on propagating testing knowledge
throughout Google and persuading developers of the value of unit testing.</p>
<p>If you don&rsquo;t have enough test automation, get started by building a skeleton
deployment pipeline. For example, create a single unit test, a single
acceptance test, and an automated deployment script that stands up an
exploratory testing environment, and thread them together. Then incrementally
increase test coverage and extend your deployment pipeline as your product or
service evolves.</p>
<p>If you&rsquo;re already working on a
<a href="https://wikipedia.org/wiki/Brownfield_%28software_development%29" target="_blank" >brownfield system</a>,
follow the guidance in this article, but don&rsquo;t stop to retrofit a comprehensive
suite of automated tests. Instead, write a small number of acceptance tests for
the high-value functionality. Then, make sure you require developers to write
unit and acceptance tests for any new functionality, and any functionality you
are changing. Consider using TDD to improve the quality and maintainability of
both main and test code, and finally, ensure that when your acceptance tests
break, you write unit tests to discover the defect faster in the future.</p>
<p>If you have a test suite that is expensive to maintain and unreliable, don&rsquo;t be
afraid to prune it down. A test suite of ten tests that is reliable, fast, and
trustworthy is much better than a test suite of hundreds of tests that is hard
to maintain and that nobody trusts.</p>
<h2 id="ways-to-measure-automated-testing">Ways to measure automated testing</h2>
<p>You can measure the results of automated testing in your environment by doing
the following:</p>
<table>
<thead>
<tr>
<th>Factor to test</th>
<th>What to measure</th>
<th>Goal</th>
</tr>
</thead>
<tbody>
<tr>
<td>Writers of acceptance and unit tests.</td>
<td>Percentage of tests written by developers, testers, and any other group in
your company.</td>
<td>Primary authors and maintainers of acceptance tests are developers.</td>
</tr>
<tr>
<td>Number of bugs found in acceptance testing, exploratory testing, and in production.</td>
<td>Change in proportion of bugs found over time.</td>
<td>More bugs are found in "cheaper" test phases, teams add automated tests
for the bugs you find during exploratory testing and production, and add unit tests to catch bugs discovered in acceptance tests..</td>
</tr>
<tr>
<td>Time spent fixing acceptance test failures.</td>
<td>Change in time spent fixing test failures over time. (It should
reduce.)</td>
<td>Developers can easily fix acceptance test failures.</td>
</tr>
<tr>
<td>Automated tests are meaningful.</td>
<td>Track the quantity of automated test failures that represent a real defect
and the quantity which were poorly coded.</td>
<td>Test failures always indicate a real defect in the product.</td>
</tr>
<tr>
<td>Automated tests run on delivery pipeline.</td>
<td>Check (yes/no) whether all test suites run in every pipeline trigger.</td>
<td>Automated tests are run as part of the main pipeline and workflow.</td>
</tr>
</tbody>
</table>
<h2 id="more-from-dora">More from DORA</h2>
<p>Read more about test automation in the following publications:</p>
<ul>
<li><a href="/capabilities/test-data-management/" >Capabilities: Test Data Management</a></li>
<li><a href="/research/2019/dora-report/" >Accelerate State of DevOps Report 2019</a></li>
<li><a href="/research/2018/dora-report/" >Accelerate State of DevOps Report 2018</a></li>
<li><a href="/research/2016/" >State of DevOps Report 2016</a></li>
<li><a href="/research/2014/" >State of DevOps Report 2014</a></li>
</ul>
<h2 id="whats-next">What&rsquo;s next</h2>
<ul>
<li>Find out more about testing at Google by reading
<a href="https://books.google.com/books/about/Software_Engineering_at_Google.html?id=WXTTDwAAQBAJ" target="_blank" >Software Engineering at Google</a>.</li>
<li>Learn how to continuously build, test, and deploy your system using
<a href="https://cloud.google.com/build/" target="_blank" >Google Cloud Build</a>.</li>
<li>Learn how to monitor your system and tests using
<a href="https://cloud.google.com/products/observability" target="_blank" >Google Cloud&rsquo;s Observability suite</a>.</li>
<li>Take the
<a href="/quickcheck/" >DORA quick check</a>
to understand where you stand in comparison with the rest of the industry.</li>
</ul>

    </article>
    <sidebar>
        <section>
            <h4>Capabilities</h4>
            <h5>Climate for Learning</h5>
            <ul>
                
                    <li><a href="/capabilities/code-maintainability/">Code maintainability</a></li>
                
                    <li><a href="/capabilities/documentation-quality/">Documentation quality</a></li>
                
                    <li><a href="/capabilities/teams-empowered-to-choose-tools/">Empowering teams to choose tools</a></li>
                
                    <li><a href="/capabilities/generative-organizational-culture/">Generative organizational culture</a></li>
                
                    <li><a href="/capabilities/job-satisfaction/">Job satisfaction</a></li>
                
                    <li><a href="/capabilities/learning-culture/">Learning culture</a></li>
                
                    <li><a href="/capabilities/team-experimentation/">Team experimentation</a></li>
                
                    <li><a href="/capabilities/transformational-leadership/">Transformational leadership</a></li>
                
                    <li><a href="/capabilities/well-being/">Well-being</a></li>
                
            </ul>
            <h5>Fast Flow</h5>
            <ul>
                
                    <li><a href="/capabilities/continuous-delivery/">Continuous delivery</a></li>
                
                    <li><a href="/capabilities/database-change-management/">Database change management</a></li>
                
                    <li><a href="/capabilities/deployment-automation/">Deployment automation</a></li>
                
                    <li><a href="/capabilities/flexible-infrastructure/">Flexible infrastructure</a></li>
                
                    <li><a href="/capabilities/loosely-coupled-teams/">Loosely coupled teams</a></li>
                
                    <li><a href="/capabilities/streamlining-change-approval/">Streamlining change approval</a></li>
                
                    <li><a href="/capabilities/trunk-based-development/">Trunk-based development</a></li>
                
                    <li><a href="/capabilities/version-control/">Version control</a></li>
                
                    <li><a href="/capabilities/visual-management/">Visual management</a></li>
                
                    <li><a href="/capabilities/wip-limits/">Work in process limits</a></li>
                
                    <li><a href="/capabilities/working-in-small-batches/">Working in small batches</a></li>
                
            </ul>
            <h5>Fast Feedback</h5>
            <ul>
                
                    <li><a href="/capabilities/continuous-integration/">Continuous integration</a></li>
                
                    <li><a href="/capabilities/customer-feedback/">Customer feedback</a></li>
                
                    <li><a href="/capabilities/monitoring-and-observability/">Monitoring and observability</a></li>
                
                    <li><a href="/capabilities/monitoring-systems/">Monitoring systems to inform business decisions</a></li>
                
                    <li><a href="/capabilities/pervasive-security/">Pervasive security</a></li>
                
                    <li><a href="/capabilities/proactive-failure-notification/">Proactive failure notification</a></li>
                
                    <li><a href="/capabilities/test-automation/">Test automation</a></li>
                
                    <li><a href="/capabilities/test-data-management/">Test data management</a></li>
                
                    <li><a href="/capabilities/work-visibility-in-value-stream/">Visibility of work in the value stream</a></li>
                
            </ul>
        </section>
    </sidebar>
</section>


<div class="updated">Last updated: July 17, 2025</div>



        </main><footer>
  <div class="container">
    <div class="logo">
      <a href="https://cloud.google.com/" target="_blank"><img src="/img/cloud-logo-dark.svg"></a>
    </div>
    <div class="links">
      <a href="/resources/">Resources</a>
      <a href="/faq/">FAQ</a>
      <a href="/contact/">Contact Us</a>
    </div>
    <div class="search">
      <form action="/search/" method="get">
        <input type="text" name="q" placeholder="Search this site">
      </form>
    </div>
    <div class="license">
      DORA is a program run by Google Cloud. All content on this site is licensed by Google LLC under <a
        href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a>, unless otherwise specified.
    </div>
    <div class="socials">
      <a class="google-material-icons" href="https://www.linkedin.com/company/doradotdev/" target="_blank"
        aria-label="Follow us on LinkedIn">post_linkedin</a>
      <a class="google-material-icons" href="https://www.youtube.com/@dora-dev" target="_blank"
        aria-label="Watch DORA videos on YouTube">post_youtube</a>
      <a class="google-material-icons" href="https://github.com/dora-team/dora.dev" target="_blank"
        aria-label="This site's source code">github</a>
    </div>
  </div>
</footer></body>
</html>